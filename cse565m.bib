@inproceedings{Ye2022,
    author = {Ye, Hanchen and Hao, Cong and Cheng, Jianyi and Jeong, Hyunmin and
              Huang, Jack and Neuendorffer, Stephen and Chen, Deming},
    booktitle = {2022 IEEE International Symposium on High-Performance Computer
                 Architecture (HPCA)},
    title = {ScaleHLS: A New Scalable High-Level Synthesis Framework on
             Multi-Level Intermediate Representation},
    year = {2022},
    pages = {741-755},
    creationdate = {2024-06-08T08:44:18},
    doi = {10.1109/HPCA53966.2022.00060},
    groups = {cse565m},
    keywords = {Productivity;Codes;Estimation;Transforms;Machine
                learning;Libraries;Hardware;High-Level
                Synthesis;MLIR;Compiler;FPGA;Optimization;Design Space
                Exploration,cse565m},
    modificationdate = {2024-06-08T08:51:42},
    owner = {Anthony Cabrera, Star Student},
}

@inproceedings{Zohouri2016,
    author = {Zohouri, Hamid Reza and Maruyama, Naoya and Smith, Aaron and
              Matsuda, Motohiko and Matsuoka, Satoshi},
    booktitle = {SC '16: Proceedings of the International Conference for High
                 Performance Computing, Networking, Storage and Analysis},
    title = {Evaluating and Optimizing OpenCL Kernels for High Performance
             Computing with FPGAs},
    year = {2016},
    month = {Nov},
    pages = {409-420},
    abstract = {We evaluate the power and performance of the Rodinia benchmark
                suite using the Altera SDK for OpenCL targeting a Stratix V FPGA
                against a modern CPU and GPU. We study multiple OpenCL kernels
                per benchmark, ranging from direct ports of the original GPU
                implementations to loop-pipelined kernels specifically optimized
                for FPGAs. Based on our results, we find that even though OpenCL
                is functionally portable across devices, direct ports of
                GPU-optimized code do not perform well compared to kernels
                optimized with FPGA-specific techniques such as sliding windows.
                However, by exploiting FPGA-specific optimizations, it is
                possible to achieve up to 3.4x better power efficiency using an
                Altera Stratix V FPGA in comparison to an NVIDIA K20c GPU, and
                better run time and power efficiency in comparison to CPU. We
                also present preliminary results for Arria 10, which, due to
                hardened FPUs, exhibits noticeably better performance compared to
                Stratix V in floating-point-intensive benchmarks.},
    creationdate = {2024-06-08T08:53:38},
    doi = {10.1109/SC.2016.34},
    groups = {cse565m},
    issn = {2167-4337},
    keywords = {Field programmable gate arrays;Kernel;Optimization;Benchmark
                testing;Programming;Graphics processing units;Performance
                evaluation;FPGA;Performance evaluation;OpenCL;Heterogeneous
                computing},
    modificationdate = {2024-06-08T08:53:38},
    owner = {Anthony Cabrera},
}

@article{zhao2024hlperf,
    title = {HLPerf: Demystifying the Performance of HLS-based Graph Neural
             Networks with Dataflow Architectures},
    author = {Zhao, Chenfeng and Faber, Clayton J and Chamberlain, Roger D and
              Zhang, Xuan},
    journal = {ACM Transactions on Reconfigurable Technology and Systems},
    year = {2024},
}

@article{sohrabizadeh2022autodse,
    title = {AutoDSE: Enabling software programmers to design efficient FPGA
             accelerators},
    author = {Sohrabizadeh, Atefeh and Yu, Cody Hao and Gao, Min and Cong, Jason
              },
    journal = {ACM Transactions on Design Automation of Electronic Systems
               (TODAES)},
    volume = {27},
    number = {4},
    pages = {1--27},
    year = {2022},
    publisher = {ACM New York, NY},
}

@article{Kastner2018,
    author = {{Kastner}, R. and {Matai}, J. and {Neuendorffer}, S.},
    journal = {ArXiv e-prints},
    title = {{Parallel Programming for FPGAs}},
    year = {2018},
    month = May,
    archiveprefix = {arXiv},
    eprint = {1805.03648},
    groups = {cse565m},
    keywords = {Computer Science - Hardware Architecture},
}

@article{SAHEBI2025107497,
    title = {HashGrid: An optimized architecture for accelerating graph
             computing on FPGAs},
    journal = {Future Generation Computer Systems},
    volume = {162},
    pages = {107497},
    year = {2025},
    issn = {0167-739X},
    doi = {https://doi.org/10.1016/j.future.2024.107497},
    url = {https://www.sciencedirect.com/science/article/pii/S0167739X24004618},
    author = {Amin Sahebi and Marco Procaccini and Roberto Giorgi},
    keywords = {Big graph computing, High-performance computing, FPGA design,
                Large-scale graph, Graph partitioning},
    abstract = {Large-scale graph processing poses challenges due to its size
                and irregular memory access patterns, causing performance
                degradation in common architectures, such as CPUs and GPUs.
                Recent research includes accelerating graph processing using
                Field Programmable Gate Arrays (FPGAs). FPGAs can provide very
                efficient acceleration thanks to reconfigurable on-chip
                resources. Although limited, these resources offer a larger
                design space than CPUs and GPUs. We propose an approach in which
                data are preprocessed in small chunks with an optimized graph
                partitioning technique for execution on FPGA accelerators. The
                chunks, located on the host, are streamed directly into a
                customized memory layer implemented in the FPGA, which is tightly
                coupled with the processing elements responsible for the graph
                algorithm execution. This improves application memory access
                latency, which is crucial in large-sale graph computing
                performance. This work presents a hardware design that, combined
                with graph partitioning, enables us to achieve high-performance
                and potentially scalable handling of large graphs (i.e., graphs
                with millions of vertices and billions of edges in current
                scenarios) while using popular graph algorithms. The proposed
                framework accelerates performance 56 times compared with CPU
                (multicore with 16 logical cores in our reference experiments),
                2.5 times and 4 times faster compared to state-of-the-art FPGA
                and GPU solutions (FPGA has 15 compute units, and GPU reference
                has 128 streaming-multiprocessors in our experiments),
                respectively, when using the PageRank algorithm. For the
                Single-Source-Shortest-Past (SSSP) algorithm, we achieve speedups
                of up to 65x, 26x, and 18x compared to CPU, GPU, and FPGA works,
                respectively. Lastly, in the context of the Weakly Connected
                Component (WCC) algorithm, our framework achieves a speedup of up
                to 403 times compared to the CPU, 7.4x against the GPU, and it is
                faster than the FPGA alternatives up to 10.3x.},
}


@INPROCEEDINGS{9221526,
  author={Singh, Gagandeep and Diamantopoulos, Dionysios and Hagleitner, Christoph and Gomez-Luna, Juan and Stuijk, Sander and Mutlu, Onur and Corporaal, Henk},
  booktitle={2020 30th International Conference on Field-Programmable Logic and Applications (FPL)}, 
  title={NERO: A Near High-Bandwidth Memory Stencil Accelerator for Weather Prediction Modeling}, 
  year={2020},
  volume={},
  number={},
  pages={9-17},
  keywords={Energy consumption;Multithreading;Weather forecasting;Predictive models;Energy efficiency;Climate change},
  doi={10.1109/FPL50879.2020.00014}}

@INPROCEEDINGS{9255725,
  author={Luthra, Siddhant and Khalid, Mohammed A.S. and Moin Oninda, Mohammad Abdul},
  booktitle={2020 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)}, 
  title={FPGA-Based Evaluation and Implementation of an Automotive RADAR Signal Processing System using High-Level Synthesis}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  keywords={Hardware;Field programmable gate arrays;Tools;Radar;Automotive engineering;Radar signal processing;Design methodology;High-Level Synthesis (HLS);Hardware Description Language (HDL);Automotive Radar Signal Processing System;Register Transfer Level (RTL);Xilinx Vivado HLS;Quality-of-Result (QoR)},
  doi={10.1109/CCECE47787.2020.9255725}}

@inproceedings{10.1145/3431920.3439290,
author = {Chen, Xinyu and Tan, Hongshi and Chen, Yao and He, Bingsheng and Wong, Weng-Fai and Chen, Deming},
title = {ThunderGP: HLS-based Graph Processing Framework on FPGAs},
year = {2021},
isbn = {9781450382182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3431920.3439290},
doi = {10.1145/3431920.3439290},
abstract = {FPGA has been an emerging computing infrastructure in datacenters benefiting from features of fine-grained parallelism, energy efficiency, and reconfigurability. Meanwhile, graph processing has attracted tremendous interest in data analytics, and its performance is in increasing demand with the rapid growth of data. Many works have been proposed to tackle the challenges of designing efficient FPGA-based accelerators for graph processing. However, the largely overlooked programmability still requires hardware design expertise and sizable development efforts from developers.In order to close the gap, we propose ThunderGP, an open-source HLS-based graph processing framework on FPGAs, with which developers could enjoy the performance of FPGA-accelerated graph processing by writing only a few high-level functions with no knowledge of the hardware. ThunderGP adopts the Gather-Apply-Scatter (GAS) model as the abstraction of various graph algorithms and realizes the model by a build-in highly-paralleled and memory-efficient accelerator template. With high-level functions as inputs, ThunderGP automatically explores the massive resources and memory bandwidth of multiple Super Logic Regions (SLRs) on FPGAs to generate accelerator and then deploys the accelerator and schedules tasks for the accelerator. We evaluate ThunderGP with seven common graph applications. The results show that accelerators on real hardware platforms deliver 2.9 times speedup over the state-of-the-art approach, running at 250MHz and achieving throughput up to 6,400 MTEPS (Million Traversed Edges Per Second). We also conduct a case study with ThunderGP, which delivers up to 419 times speedup over the CPU-based design and requires significantly reduced development efforts. This work is open-sourced on Github at https://github.com/Xtra-Computing/ThunderGP.},
booktitle = {The 2021 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {69–80},
numpages = {12},
keywords = {fpga, framework, graph processing, high-level synthesis, multiple super logic regions},
location = {Virtual Event, USA},
series = {FPGA '21}
}



@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:cse565m\;0\;1\;\;\;\;;
}

